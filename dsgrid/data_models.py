"""Base functionality for all Pydantic data models used in dsgrid"""

import enum
import json
import logging
import os
from datetime import datetime, timedelta
from pathlib import Path

from pydantic import BaseModel, ValidationError
from pydantic.json import isoformat, timedelta_isoformat
from semver import VersionInfo

from dsgrid.utils.files import load_data


logger = logging.getLogger(__name__)


class DSGBaseModel(BaseModel):
    """Base data model for all dsgrid data models"""

    class Config:
        title = "DSGBaseModel"
        anystr_strip_whitespace = True
        validate_assignment = True
        validate_all = True
        extra = "forbid"
        use_enum_values = False
        arbitrary_types_allowed = True
        allow_population_by_field_name = True

    @classmethod
    def load(cls, filename):
        """Load a data model from a file.
        Temporarily changes to the file's parent directory so that Pydantic
        validators can load relative file paths within the file.

        Parameters
        ----------
        filename : str

        """
        filename = Path(filename)
        base_dir = filename.parent.absolute()
        orig = os.getcwd()
        os.chdir(base_dir)
        try:
            cfg = cls(**load_data(filename.name))
            return cfg
        except ValidationError:
            logger.exception("Failed to validate %s", filename)
            raise
        finally:
            os.chdir(orig)

    @classmethod
    def schema_json(cls, by_alias=True, indent=None) -> str:
        data = cls.schema(by_alias=by_alias)
        return json.dumps(data, indent=indent, cls=ExtendedJSONEncoder)

    @classmethod
    def get_fields_with_extra_attribute(cls, attribute):
        fields = set()
        for f, attrs in cls.__fields__.items():
            if attrs.field_info.extra.get(attribute):
                fields.add(f)
        return fields


class ExtendedJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, VersionInfo):
            return str(obj)
        if isinstance(obj, enum.Enum):
            return obj.value
        if isinstance(obj, datetime):
            return isoformat(obj)
        if isinstance(obj, timedelta):
            return timedelta_isoformat(obj)

        return json.JSONEncoder.default(self, obj)


def serialize_model(model: DSGBaseModel, by_alias=True, exclude=None):
    """Serialize a model to a dict, converting values as needed.

    Parameters
    ----------
    by_alias : bool
        Forwarded to pydantic.BaseModel.dict.
    exclude : set
        Forwarded to pydantic.BaseModel.dict.

    """
    # TODO: we should be able to use model.json and custom JSON encoders
    # instead of doing this, at least in most cases.
    return serialize_model_data(model.dict(by_alias=by_alias, exclude=exclude))


def serialize_user_model(model: DSGBaseModel):
    """Serialize the user model to a dict, converting values as needed and ignoring fields generated by dsgrid."""
    # TODO: we should be able to use model.json and custom JSON encoders
    # instead of doing this, at least in most cases.
    exclude = type(model).get_fields_with_extra_attribute("dsg_internal")
    return serialize_model_data(model.dict(by_alias=True, exclude=exclude))


def serialize_model_data(data: dict):
    for key, val in data.items():
        data[key] = _serialize_model_item(val)
    return data


def _serialize_model_item(val):
    if isinstance(val, enum.Enum):
        return val.value
    if isinstance(val, VersionInfo):
        return str(val)
    if isinstance(val, datetime):
        return isoformat(val)
    if isinstance(val, timedelta):
        return timedelta_isoformat(val)
    if isinstance(val, dict):
        return serialize_model_data(val)
    if isinstance(val, list):
        return [_serialize_model_item(x) for x in val]
    return val
